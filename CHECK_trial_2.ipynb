{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQ5wFjkmJTYAj3c5Hcuw0X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"75jS6JQEKPUP"},"outputs":[],"source":[]},{"cell_type":"code","source":["\n","# ======================= CHECK MODEL =======================\n","class CHECK:\n","    def __init__(self, llm, tok, device):\n","        self.llm = llm\n","        self.tok = tok\n","        self.device = device\n","        self.edits = []\n","        self.embeds = []\n","\n","        self.contriever = AutoModel.from_pretrained(\"facebook/contriever-msmarco\").to(device)\n","        self.c_tok = AutoTokenizer.from_pretrained(\"facebook/contriever-msmarco\")\n","\n","    def add_edits(self, edits):\n","        self.edits = edits\n","        sr = [f\"{s} {r}\" for s,r,_ in edits]\n","        self.embeds = get_sent_embeddings(sr, self.contriever, self.c_tok, self.device)\n","\n","    def llm_call(self, prompt):\n","        inp = self.tok(prompt, return_tensors=\"pt\").to(self.device)\n","        out = self.llm.generate(**inp, max_new_tokens=32, do_sample=False)\n","        return self.tok.decode(out[0], skip_special_tokens=True)[len(prompt):].strip()\n","\n","    def check_edit(self, s, r):\n","        q = get_sent_embeddings([f\"{s} {r}\"], self.contriever, self.c_tok, self.device)\n","        best, score = None, 0\n","        for i,e in enumerate(self.embeds):\n","            sim = cosine_sim(q, e.unsqueeze(0)).item()\n","            if sim > score and sim > 0.75:\n","                best = self.edits[i][2]\n","                score = sim\n","        return best\n","\n","    def answer(self, question):\n","        s = extract_entity(question)\n","        if not s: return None\n","\n","        rels = self.llm_call(f\"Extract relations from question:\\n{question}\\nRelations:\")\n","        rels = [r.strip() for r in rels.split(\"|\") if r.strip()]\n","\n","        for r in rels:\n","            edited = self.check_edit(s, r)\n","            if edited:\n","                s = edited\n","                continue\n","            q = self.llm_call(f\"Convert to question:\\n{s} {r}\\nQ:\")\n","            s = self.llm_call(f\"Answer factually:\\n{q}\\nA:\")\n","        return s\n"],"metadata":{"id":"B3k8_w2gnujZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================= LOAD LLM =======================\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","MODEL = \"tiiuae/falcon-7b-instruct\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","tokenizer.pad_token = tokenizer.eos_token\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL,\n","    device_map=\"auto\",\n","    offload_folder=\"./offload\",\n","    torch_dtype=torch.float16,\n","    low_cpu_mem_usage=True\n",")\n","\n","checker = CHECK(model, tokenizer, DEVICE)\n","len(checker.model)\n","plt.rcParams['figure.figsize'] = [10, 5]\n","checker\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":194,"referenced_widgets":["f31c20c187fc47c8b9d19b93a3181162","7c36e27e646b49a3a86380082dc16599","8d7709d6e70340468631a414ef786b33","148cb381dc694575871a53a96023beb3","ae3cb1f118db4535a73528f9672e4e10","014488ecdbe84c38b523d56b80d62c39","470b148fc5e845399dc4b6176114dbbc","3c17cb56a7904c97a2fc981c6fed6b3e","a7bd16daf3114c88958cae53cf4dbb6b","4797d5301f1c4972b124fe248bf901f5","232435bfd6654450bc7a33bd45ad3a9c"]},"id":"P5Q0Pauxny-G","executionInfo":{"status":"ok","timestamp":1766585245378,"user_tz":-330,"elapsed":79059,"user":{"displayName":"Aditya","userId":"16350885099440970273"}},"outputId":"a66159fa-e9a1-4d64-9163-fe03b058ce3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","`torch_dtype` is deprecated! Use `dtype` instead!\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f31c20c187fc47c8b9d19b93a3181162"}},"metadata":{}}]},{"cell_type":"code","source":["\n","# ======================= EVALUATION =======================\n","case_correct = 0\n","q_correct = 0\n","q_total = 0\n","\n","for case in DATA:\n","    edits = []\n","    for rw in case[\"requested_rewrite\"]:\n","        edits.append((rw[\"subject\"], rw[\"relation_id\"], rw[\"target_new\"][\"str\"]))\n","    checker.add_edits(edits)\n","\n","    hit = False\n","    for q in case[\"questions\"]:\n","        q_total += 1\n","        pred = checker.answer(q)\n","        gold = case[\"new_answer\"]\n","        golds = [gold[\"answer\"]] if isinstance(gold, dict) else [gold]\n","\n","        if pred and any(g.lower() in pred.lower() for g in golds):\n","            q_correct += 1\n","            hit = True\n","\n","    if hit:\n","        case_correct += 1\n","\n","print(\"\\nFINAL RESULTS\")\n","print(\"Per-case accuracy:\", case_correct / len(DATA))\n","print(\"Per-question accuracy:\", q_correct / q_total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HVFdjFpRn2UH","executionInfo":{"status":"error","timestamp":1766587119193,"user_tz":-330,"elapsed":272785,"user":{"displayName":"Aditya","userId":"16350885099440970273"}},"outputId":"75c53c18-e6d0-4306-8474-391e1c423586"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3429749294.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"questions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mq_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"new_answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mgolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1228930891.py\u001b[0m in \u001b[0;36manswer\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extract relations from question:\\n{question}\\nRelations:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1228930891.py\u001b[0m in \u001b[0;36mllm_call\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mllm_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/falcon/modeling_falcon.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1045\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/falcon/modeling_falcon.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m             outputs = block(\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/falcon/modeling_falcon.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, alibi, attention_mask, position_ids, layer_past, head_mask, use_cache, output_attentions, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;31m# Self attention.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         attention_output, attn_weights = self.self_attention(\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mattention_layernorm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/falcon/modeling_falcon.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, alibi, attention_mask, position_ids, layer_past, head_mask, use_cache, output_attentions, cache_position, position_embeddings)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_kv_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_kv_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["query_size == batch_size is the most important condition for the model"],"metadata":{"id":"OZuccvZxy8ao"},"execution_count":null,"outputs":[]}]}